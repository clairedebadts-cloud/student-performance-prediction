{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Student Test Scores - Fixed Pipeline + Optuna Optimization\n",
    "\n",
    "This notebook:\n",
    "1. âœ… Fixes the feature encoding issue\n",
    "2. âœ… Implements proper feature engineering\n",
    "3. âœ… Uses Optuna for hyperparameter optimization\n",
    "4. âœ… Generates a valid submission file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## 1. Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n",
      "Optuna version: 4.7.0\n",
      "LightGBM version: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_parallel_coordinate\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(f\"LightGBM version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "âœ“ Data loaded\n",
      "  Train shape: (630000, 13)\n",
      "  Test shape: (270000, 12)\n",
      "\n",
      "Features: ['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance', 'internet_access', 'sleep_hours', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty', 'exam_score']\n",
      "\n",
      "Target stats:\n",
      "count    630000.000000\n",
      "mean         62.506672\n",
      "std          18.916884\n",
      "min          19.599000\n",
      "25%          48.800000\n",
      "50%          62.600000\n",
      "75%          76.300000\n",
      "max         100.000000\n",
      "Name: exam_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(f\"âœ“ Data loaded\")\n",
    "print(f\"  Train shape: {train.shape}\")\n",
    "print(f\"  Test shape: {test.shape}\")\n",
    "\n",
    "print(f\"\\nFeatures: {train.columns.tolist()}\")\n",
    "print(f\"\\nTarget stats:\")\n",
    "print(train['exam_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>internet_access</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>study_method</th>\n",
       "      <th>facility_rating</th>\n",
       "      <th>exam_difficulty</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>7.91</td>\n",
       "      <td>98.8</td>\n",
       "      <td>no</td>\n",
       "      <td>4.9</td>\n",
       "      <td>average</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>78.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>other</td>\n",
       "      <td>diploma</td>\n",
       "      <td>4.95</td>\n",
       "      <td>94.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.7</td>\n",
       "      <td>poor</td>\n",
       "      <td>self-study</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>4.68</td>\n",
       "      <td>92.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.8</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>2.00</td>\n",
       "      <td>49.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.3</td>\n",
       "      <td>average</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>bca</td>\n",
       "      <td>7.65</td>\n",
       "      <td>86.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.6</td>\n",
       "      <td>good</td>\n",
       "      <td>self-study</td>\n",
       "      <td>high</td>\n",
       "      <td>easy</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  gender   course  study_hours  class_attendance internet_access  \\\n",
       "0   0   21  female     b.sc         7.91              98.8              no   \n",
       "1   1   18   other  diploma         4.95              94.8             yes   \n",
       "2   2   20  female     b.sc         4.68              92.6             yes   \n",
       "3   3   19    male     b.sc         2.00              49.5             yes   \n",
       "4   4   23    male      bca         7.65              86.9             yes   \n",
       "\n",
       "   sleep_hours sleep_quality   study_method facility_rating exam_difficulty  \\\n",
       "0          4.9       average  online videos             low            easy   \n",
       "1          4.7          poor     self-study          medium        moderate   \n",
       "2          5.8          poor       coaching            high        moderate   \n",
       "3          8.3       average    group study            high        moderate   \n",
       "4          9.6          good     self-study            high            easy   \n",
       "\n",
       "   exam_score  \n",
       "0        78.3  \n",
       "1        46.7  \n",
       "2        99.0  \n",
       "3        63.9  \n",
       "4       100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>internet_access</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>study_method</th>\n",
       "      <th>facility_rating</th>\n",
       "      <th>exam_difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630000</td>\n",
       "      <td>24</td>\n",
       "      <td>other</td>\n",
       "      <td>ba</td>\n",
       "      <td>6.85</td>\n",
       "      <td>65.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.2</td>\n",
       "      <td>poor</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630001</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>diploma</td>\n",
       "      <td>6.61</td>\n",
       "      <td>45.0</td>\n",
       "      <td>no</td>\n",
       "      <td>9.3</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630002</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>6.60</td>\n",
       "      <td>98.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>6.2</td>\n",
       "      <td>good</td>\n",
       "      <td>group study</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630003</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>diploma</td>\n",
       "      <td>3.03</td>\n",
       "      <td>66.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.7</td>\n",
       "      <td>average</td>\n",
       "      <td>mixed</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630004</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>2.03</td>\n",
       "      <td>42.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.2</td>\n",
       "      <td>average</td>\n",
       "      <td>coaching</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  age  gender   course  study_hours  class_attendance  \\\n",
       "0  630000   24   other       ba         6.85              65.2   \n",
       "1  630001   18    male  diploma         6.61              45.0   \n",
       "2  630002   24  female   b.tech         6.60              98.5   \n",
       "3  630003   24    male  diploma         3.03              66.3   \n",
       "4  630004   20  female   b.tech         2.03              42.4   \n",
       "\n",
       "  internet_access  sleep_hours sleep_quality study_method facility_rating  \\\n",
       "0             yes          5.2          poor  group study            high   \n",
       "1              no          9.3          poor     coaching             low   \n",
       "2             yes          6.2          good  group study          medium   \n",
       "3             yes          5.7       average        mixed          medium   \n",
       "4             yes          9.2       average     coaching             low   \n",
       "\n",
       "  exam_difficulty  \n",
       "0            easy  \n",
       "1            easy  \n",
       "2        moderate  \n",
       "3        moderate  \n",
       "4        moderate  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview data\n",
    "print(\"Training data preview:\")\n",
    "display(train.head())\n",
    "\n",
    "print(\"\\nTest data preview:\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_engineering_header",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "**CRITICAL:** We apply the same transformations to both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering_function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Feature engineering function defined\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Apply feature engineering transformations.\n",
    "    This function is applied to both train and test to ensure consistency.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Polynomial features\n",
    "    df['study_hours_sq'] = df['study_hours'] ** 2\n",
    "    df['sleep_hours_sq'] = df['sleep_hours'] ** 2\n",
    "    df['class_attendance_sq'] = df['class_attendance'] ** 2\n",
    "    \n",
    "    # Interaction features\n",
    "    df['study_attendance'] = df['study_hours'] * df['class_attendance']\n",
    "    df['study_sleep_ratio'] = df['study_hours'] / (df['sleep_hours'] + 1e-6)\n",
    "    df['age_study_interaction'] = df['age'] * df['study_hours']\n",
    "    df['attendance_sleep'] = df['class_attendance'] * df['sleep_hours']\n",
    "    \n",
    "    # Categorical binning\n",
    "    df['age_group'] = pd.cut(df['age'], \n",
    "                              bins=[0, 22, 28, 100], \n",
    "                              labels=['young', 'middle', 'senior'])\n",
    "    \n",
    "    df['study_intensity'] = pd.cut(df['study_hours'],\n",
    "                                     bins=[0, 3, 6, 100],\n",
    "                                     labels=['low', 'medium', 'high'])\n",
    "    \n",
    "    df['sleep_category'] = pd.cut(df['sleep_hours'],\n",
    "                                    bins=[0, 6, 8, 100],\n",
    "                                    labels=['insufficient', 'optimal', 'excessive'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ“ Feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train features: (630000, 11)\n",
      "Original test features: (270000, 11)\n",
      "\n",
      "Applying feature engineering...\n",
      "After feature engineering:\n",
      "  Train: (630000, 21)\n",
      "  Test: (270000, 21)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X_train_full = train.drop(['id', 'exam_score'], axis=1)\n",
    "y_train = train['exam_score']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "test_ids = test['id']\n",
    "\n",
    "print(f\"Original train features: {X_train_full.shape}\")\n",
    "print(f\"Original test features: {X_test.shape}\")\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"\\nApplying feature engineering...\")\n",
    "X_train_full = engineer_features(X_train_full)\n",
    "X_test = engineer_features(X_test)\n",
    "\n",
    "print(f\"After feature engineering:\")\n",
    "print(f\"  Train: {X_train_full.shape}\")\n",
    "print(f\"  Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoding_header",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Variables\n",
    "\n",
    "**THE FIX:** Combine train and test before encoding to ensure identical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables...\n",
      "Combined shape: (900000, 21)\n",
      "After encoding: (900000, 36)\n",
      "\n",
      "âœ“ Encoding complete\n",
      "  Train shape: (630000, 36)\n",
      "  Test shape: (270000, 36)\n",
      "  Columns match: True\n",
      "  Number of features: 36\n",
      "\n",
      "Missing values:\n",
      "  Train: 0\n",
      "  Test: 0\n",
      "\n",
      "âœ“ All validation checks passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding categorical variables...\")\n",
    "\n",
    "# Combine train and test with keys to track them\n",
    "combined = pd.concat([X_train_full, X_test], keys=['train', 'test'], sort=False)\n",
    "\n",
    "print(f\"Combined shape: {combined.shape}\")\n",
    "\n",
    "# One-hot encode\n",
    "combined_encoded = pd.get_dummies(combined, drop_first=True)\n",
    "\n",
    "print(f\"After encoding: {combined_encoded.shape}\")\n",
    "\n",
    "# Split back into train and test\n",
    "X_train_encoded = combined_encoded.loc['train'].reset_index(drop=True)\n",
    "X_test_encoded = combined_encoded.loc['test'].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ“ Encoding complete\")\n",
    "print(f\"  Train shape: {X_train_encoded.shape}\")\n",
    "print(f\"  Test shape: {X_test_encoded.shape}\")\n",
    "print(f\"  Columns match: {X_train_encoded.shape[1] == X_test_encoded.shape[1]}\")\n",
    "print(f\"  Number of features: {X_train_encoded.shape[1]}\")\n",
    "\n",
    "# Verify no missing values\n",
    "train_nulls = X_train_encoded.isnull().sum().sum()\n",
    "test_nulls = X_test_encoded.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(f\"  Train: {train_nulls}\")\n",
    "print(f\"  Test: {test_nulls}\")\n",
    "\n",
    "assert train_nulls == 0, \"Train has missing values!\"\n",
    "assert test_nulls == 0, \"Test has missing values!\"\n",
    "\n",
    "print(\"\\nâœ“ All validation checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display_features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns (36):\n",
      "['age', 'study_hours', 'class_attendance', 'sleep_hours', 'study_hours_sq', 'sleep_hours_sq', 'class_attendance_sq', 'study_attendance', 'study_sleep_ratio', 'age_study_interaction', 'attendance_sleep', 'gender_male', 'gender_other', 'course_b.sc', 'course_b.tech', 'course_ba', 'course_bba', 'course_bca', 'course_diploma', 'internet_access_yes', 'sleep_quality_good', 'sleep_quality_poor', 'study_method_group study', 'study_method_mixed', 'study_method_online videos', 'study_method_self-study', 'facility_rating_low', 'facility_rating_medium', 'exam_difficulty_hard', 'exam_difficulty_moderate', 'age_group_middle', 'age_group_senior', 'study_intensity_medium', 'study_intensity_high', 'sleep_category_optimal', 'sleep_category_excessive']\n"
     ]
    }
   ],
   "source": [
    "# Display feature names\n",
    "print(f\"Feature columns ({len(X_train_encoded.columns)}):\")\n",
    "print(X_train_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_val_split_header",
   "metadata": {},
   "source": [
    "## 5. Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_val_split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (504000, 36)\n",
      "Validation set: (126000, 36)\n",
      "Test set: (270000, 36)\n"
     ]
    }
   ],
   "source": [
    "# Split for validation\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train_encoded, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_header",
   "metadata": {},
   "source": [
    "## 6. Baseline Model (Before Optuna)\n",
    "\n",
    "Let's establish a baseline with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n",
      "\n",
      "============================================================\n",
      "BASELINE MODEL RESULTS\n",
      "============================================================\n",
      "Training RMSE:   8.8028\n",
      "Validation RMSE: 8.8216\n",
      "Validation MAE:  7.0442\n",
      "Validation RÂ²:   0.7812\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training baseline model...\")\n",
    "\n",
    "# Baseline LightGBM with default parameters\n",
    "baseline_model = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train, y_train_split)\n",
    "\n",
    "# Evaluate\n",
    "train_preds = baseline_model.predict(X_train)\n",
    "val_preds = baseline_model.predict(X_val)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_split, train_preds))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "val_mae = mean_absolute_error(y_val, val_preds)\n",
    "val_r2 = r2_score(y_val, val_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE MODEL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training RMSE:   {train_rmse:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Validation MAE:  {val_mae:.4f}\")\n",
    "print(f\"Validation RÂ²:   {val_r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_score = val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna_header",
   "metadata": {},
   "source": [
    "## 7. Optuna Hyperparameter Optimization\n",
    "\n",
    "Now let's use Optuna to find better hyperparameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_objective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Objective function defined\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize.\n",
    "    Optuna will try to minimize the returned value (RMSE).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        \n",
    "        # Hyperparameters to optimize\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train_split)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "print(\"âœ“ Objective function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_optimize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Optuna study...\n",
      "\n",
      "Starting hyperparameter optimization...\n",
      "This may take a few minutes depending on n_trials.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c3930cfd5947d39542d1a9f5d93b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OPTIMIZATION COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study\n",
    "print(\"Creating Optuna study...\\n\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',  # Minimize RMSE\n",
    "    study_name='student_scores_optimization',\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "print(\"This may take a few minutes depending on n_trials.\\n\")\n",
    "\n",
    "# Change n_trials based on your time budget:\n",
    "# - 20-30 trials: Quick test (~5-10 minutes)\n",
    "# - 50-100 trials: Good results (~15-30 minutes)\n",
    "# - 200+ trials: Best results (longer)\n",
    "\n",
    "N_TRIALS = 50  # Adjust this as needed\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna_results_header",
   "metadata": {},
   "source": [
    "## 8. Optuna Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best trial results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST TRIAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best RMSE: {study.best_value:.4f}\")\n",
    "print(f\"Baseline RMSE: {baseline_score:.4f}\")\n",
    "print(f\"Improvement: {baseline_score - study.best_value:.4f} ({(baseline_score - study.best_value)/baseline_score*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "print(f\"\\nNumber of trials: {len(study.trials)}\")\n",
    "print(f\"Best trial number: {study.best_trial.number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_viz_history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.update_layout(\n",
    "    title=\"Optimization History: How RMSE improved over trials\",\n",
    "    width=900,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_viz_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Parameter Importance\n",
    "fig = plot_param_importances(study)\n",
    "fig.update_layout(\n",
    "    title=\"Hyperparameter Importance: Which parameters matter most?\",\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_viz_parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Parallel Coordinate Plot\n",
    "fig = plot_parallel_coordinate(study)\n",
    "fig.update_layout(\n",
    "    title=\"Parallel Coordinate Plot: Relationship between parameters and RMSE\",\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trials_dataframe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 trials\n",
    "trials_df = study.trials_dataframe().sort_values('value').head(10)\n",
    "print(\"\\nTop 10 Trials:\")\n",
    "display(trials_df[['number', 'value', 'params_learning_rate', 'params_max_depth', \n",
    "                    'params_n_estimators', 'params_num_leaves']].style.background_gradient(cmap='RdYlGn_r', subset=['value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_model_header",
   "metadata": {},
   "source": [
    "## 9. Train Final Model with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training final model with best parameters on full training data...\\n\")\n",
    "\n",
    "# Create final model with best parameters\n",
    "final_model = lgb.LGBMRegressor(**study.best_params, random_state=RANDOM_STATE, verbose=-1)\n",
    "\n",
    "# Train on full training data\n",
    "final_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate on validation set one more time\n",
    "final_val_preds = final_model.predict(X_val)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_val, final_val_preds))\n",
    "final_mae = mean_absolute_error(y_val, final_val_preds)\n",
    "final_r2 = r2_score(y_val, final_val_preds)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Validation RMSE: {final_rmse:.4f}\")\n",
    "print(f\"Validation MAE:  {final_mae:.4f}\")\n",
    "print(f\"Validation RÂ²:   {final_r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ“ Final model trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_importance_header",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_encoded.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "display(feature_importance.head(20))\n",
    "\n",
    "# Visualize top features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 20 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predictions_header",
   "metadata": {},
   "source": [
    "## 11. Generate Predictions & Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating predictions on test set...\\n\")\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = final_model.predict(X_test_encoded)\n",
    "\n",
    "print(f\"âœ“ Predictions generated: {len(test_predictions)}\")\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Min:    {test_predictions.min():.4f}\")\n",
    "print(f\"  Max:    {test_predictions.max():.4f}\")\n",
    "print(f\"  Mean:   {test_predictions.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(test_predictions):.4f}\")\n",
    "print(f\"  Std:    {test_predictions.std():.4f}\")\n",
    "\n",
    "# Compare with training distribution\n",
    "print(f\"\\nTraining target statistics:\")\n",
    "print(f\"  Min:    {y_train.min():.4f}\")\n",
    "print(f\"  Max:    {y_train.max():.4f}\")\n",
    "print(f\"  Mean:   {y_train.mean():.4f}\")\n",
    "print(f\"  Median: {y_train.median():.4f}\")\n",
    "print(f\"  Std:    {y_train.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Histogram comparison\n",
    "axes[0].hist(y_train, bins=50, alpha=0.7, label='Training Target', edgecolor='black', color='blue')\n",
    "axes[0].hist(test_predictions, bins=50, alpha=0.7, label='Test Predictions', edgecolor='black', color='orange')\n",
    "axes[0].set_xlabel('Exam Score', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Training vs Test Predictions Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot comparison\n",
    "data_to_plot = [y_train, test_predictions]\n",
    "axes[1].boxplot(data_to_plot, labels=['Training', 'Test Predictions'])\n",
    "axes[1].set_ylabel('Exam Score', fontsize=12)\n",
    "axes[1].set_title('Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'exam_score': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Validating submission...\")\n",
    "\n",
    "# Validation checks\n",
    "assert len(submission) == len(test), f\"Expected {len(test)} rows, got {len(submission)}\"\n",
    "assert list(submission.columns) == ['id', 'exam_score'], \"Wrong column names\"\n",
    "assert submission['exam_score'].notna().all(), \"Has missing predictions\"\n",
    "assert submission['id'].nunique() == len(submission), \"Has duplicate IDs\"\n",
    "assert (submission['exam_score'] >= 0).all(), \"Has negative predictions\"\n",
    "assert (submission['exam_score'] <= 120).all(), \"Has predictions > 120\"\n",
    "\n",
    "print(\"\\nâœ“ All validation checks passed!\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission_optuna.csv', index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUBMISSION FILE CREATED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Filename: submission_optuna.csv\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"File size: ~{submission.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "display(submission.head(10))\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Ready to submit to Kaggle!\")\n",
    "print(f\"Expected leaderboard RMSE: ~{final_rmse:.4f} (may vary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## 12. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"NOTEBOOK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nâœ“ Data loaded: {len(train):,} training samples, {len(test):,} test samples\")\n",
    "print(f\"âœ“ Features engineered: {X_train_encoded.shape[1]} total features\")\n",
    "print(f\"âœ“ Categorical encoding: Fixed and aligned between train/test\")\n",
    "print(f\"âœ“ Baseline RMSE: {baseline_score:.4f}\")\n",
    "print(f\"âœ“ Optuna trials: {len(study.trials)}\")\n",
    "print(f\"âœ“ Best RMSE: {study.best_value:.4f}\")\n",
    "print(f\"âœ“ Improvement: {(baseline_score - study.best_value)/baseline_score*100:.2f}%\")\n",
    "print(f\"âœ“ Submission file: submission_optuna.csv\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"NEXT STEPS TO IMPROVE YOUR SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. Run more Optuna trials (100-200) for better optimization\n",
    "2. Try different feature engineering:\n",
    "   - More interaction features\n",
    "   - Different binning strategies\n",
    "   - Log/sqrt transformations\n",
    "\n",
    "3. Ensemble methods:\n",
    "   - Train multiple models and average predictions\n",
    "   - Try XGBoost or CatBoost alongside LightGBM\n",
    "   - Stacking different model types\n",
    "\n",
    "4. Cross-validation:\n",
    "   - Use 5-fold or 10-fold CV in Optuna objective\n",
    "   - More robust evaluation\n",
    "\n",
    "5. Advanced techniques:\n",
    "   - Target encoding for categorical features\n",
    "   - Pseudo-labeling (use test predictions as extra training)\n",
    "   - Outlier handling\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nGood luck on the leaderboard! ðŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optional: Save Best Model & Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(final_model, 'best_model_optuna.pkl')\n",
    "print(\"âœ“ Model saved to: best_model_optuna.pkl\")\n",
    "\n",
    "# Save Optuna study for later analysis\n",
    "joblib.dump(study, 'optuna_study.pkl')\n",
    "print(\"âœ“ Optuna study saved to: optuna_study.pkl\")\n",
    "\n",
    "# Save best parameters as JSON\n",
    "import json\n",
    "\n",
    "with open('best_params.json', 'w') as f:\n",
    "    json.dump(study.best_params, f, indent=2)\n",
    "print(\"âœ“ Best parameters saved to: best_params.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
