{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Ensemble Model - Target: Break into Top 5\n",
    "\n",
    "**Current Score:** 8.737  \n",
    "**Target Score:** 8.53 (Top 5)  \n",
    "**Gap:** 0.204 points\n",
    "\n",
    "**Strategy:**\n",
    "1. Train 3 different models with Optuna\n",
    "2. Ensemble predictions with optimal weights\n",
    "3. Use cross-validation for robustness\n",
    "\n",
    "Expected improvement: **0.10-0.20 points** âœ¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install optuna xgboost catboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ML utilities\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "%matplotlib inline\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ“ Libraries imported\")\n",
    "print(f\"LightGBM: {lgb.__version__}\")\n",
    "print(f\"XGBoost: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_header",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "Using the same preprocessing as before (ensuring consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Feature engineering - same as Optuna notebook\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Polynomial features\n",
    "    df['study_hours_sq'] = df['study_hours'] ** 2\n",
    "    df['sleep_hours_sq'] = df['sleep_hours'] ** 2\n",
    "    df['class_attendance_sq'] = df['class_attendance'] ** 2\n",
    "    \n",
    "    # Interaction features\n",
    "    df['study_attendance'] = df['study_hours'] * df['class_attendance']\n",
    "    df['study_sleep_ratio'] = df['study_hours'] / (df['sleep_hours'] + 1e-6)\n",
    "    df['age_study_interaction'] = df['age'] * df['study_hours']\n",
    "    df['attendance_sleep'] = df['class_attendance'] * df['sleep_hours']\n",
    "    \n",
    "    # Categorical binning\n",
    "    df['age_group'] = pd.cut(df['age'], bins=[0, 22, 28, 100], \n",
    "                              labels=['young', 'middle', 'senior'])\n",
    "    df['study_intensity'] = pd.cut(df['study_hours'], bins=[0, 3, 6, 100],\n",
    "                                     labels=['low', 'medium', 'high'])\n",
    "    df['sleep_category'] = pd.cut(df['sleep_hours'], bins=[0, 6, 8, 100],\n",
    "                                    labels=['insufficient', 'optimal', 'excessive'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare data\n",
    "X_train_full = train.drop(['id', 'exam_score'], axis=1)\n",
    "y_train = train['exam_score']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "test_ids = test['id']\n",
    "\n",
    "# Apply feature engineering\n",
    "X_train_full = engineer_features(X_train_full)\n",
    "X_test = engineer_features(X_test)\n",
    "\n",
    "# Encode (combine first to ensure matching columns)\n",
    "combined = pd.concat([X_train_full, X_test], keys=['train', 'test'])\n",
    "combined_encoded = pd.get_dummies(combined, drop_first=True)\n",
    "X_train_encoded = combined_encoded.loc['train'].reset_index(drop=True)\n",
    "X_test_encoded = combined_encoded.loc['test'].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ“ Data prepared\")\n",
    "print(f\"Train: {X_train_encoded.shape}\")\n",
    "print(f\"Test: {X_test_encoded.shape}\")\n",
    "print(f\"Features: {X_train_encoded.shape[1]}\")\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train_encoded, y_train, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model1_header",
   "metadata": {},
   "source": [
    "## 2. Model 1: LightGBM with Extended Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lgb_optuna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train_split)\n",
    "    preds = model.predict(X_val)\n",
    "    return np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "print(\"Optimizing LightGBM...\")\n",
    "lgb_study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "lgb_study.optimize(lgb_objective, n_trials=100, show_progress_bar=True)  # Increased trials!\n",
    "\n",
    "print(f\"\\nâœ“ LightGBM Best RMSE: {lgb_study.best_value:.4f}\")\n",
    "print(f\"Best params: {lgb_study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model2_header",
   "metadata": {},
   "source": [
    "## 3. Model 2: XGBoost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgb_optuna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train_split, verbose=False)\n",
    "    preds = model.predict(X_val)\n",
    "    return np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "print(\"Optimizing XGBoost...\")\n",
    "xgb_study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "xgb_study.optimize(xgb_objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nâœ“ XGBoost Best RMSE: {xgb_study.best_value:.4f}\")\n",
    "print(f\"Best params: {xgb_study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model3_header",
   "metadata": {},
   "source": [
    "## 4. Model 3: CatBoost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat_optuna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': False,\n",
    "        'iterations': trial.suggest_int('iterations', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train_split)\n",
    "    preds = model.predict(X_val)\n",
    "    return np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "print(\"Optimizing CatBoost...\")\n",
    "cat_study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "cat_study.optimize(cat_objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nâœ“ CatBoost Best RMSE: {cat_study.best_value:.4f}\")\n",
    "print(f\"Best params: {cat_study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare_header",
   "metadata": {},
   "source": [
    "## 5. Compare Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models with best params\n",
    "print(\"Training final models on full training data...\\n\")\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**lgb_study.best_params, random_state=RANDOM_STATE, verbosity=-1)\n",
    "xgb_model = xgb.XGBRegressor(**xgb_study.best_params, random_state=RANDOM_STATE)\n",
    "cat_model = CatBoostRegressor(**cat_study.best_params, random_state=RANDOM_STATE, verbose=False)\n",
    "\n",
    "lgb_model.fit(X_train_encoded, y_train)\n",
    "xgb_model.fit(X_train_encoded, y_train)\n",
    "cat_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate on validation\n",
    "lgb_val_pred = lgb_model.predict(X_val)\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "cat_val_pred = cat_model.predict(X_val)\n",
    "\n",
    "lgb_rmse = np.sqrt(mean_squared_error(y_val, lgb_val_pred))\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_val, xgb_val_pred))\n",
    "cat_rmse = np.sqrt(mean_squared_error(y_val, cat_val_pred))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INDIVIDUAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"LightGBM RMSE: {lgb_rmse:.4f}\")\n",
    "print(f\"XGBoost RMSE:  {xgb_rmse:.4f}\")\n",
    "print(f\"CatBoost RMSE: {cat_rmse:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "model_names = ['LightGBM', 'XGBoost', 'CatBoost']\n",
    "rmses = [lgb_rmse, xgb_rmse, cat_rmse]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(model_names, rmses, color=['steelblue', 'orange', 'green'], alpha=0.7, edgecolor='black')\n",
    "plt.ylabel('Validation RMSE', fontsize=12)\n",
    "plt.title('Individual Model Performance', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, rmse in zip(bars, rmses):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{rmse:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble_header",
   "metadata": {},
   "source": [
    "## 6. Optimize Ensemble Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ensemble_weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_objective(trial):\n",
    "    \"\"\"Find optimal weights for ensemble\"\"\"\n",
    "    w1 = trial.suggest_float('lgb_weight', 0.0, 1.0)\n",
    "    w2 = trial.suggest_float('xgb_weight', 0.0, 1.0)\n",
    "    w3 = trial.suggest_float('cat_weight', 0.0, 1.0)\n",
    "    \n",
    "    # Normalize weights\n",
    "    total = w1 + w2 + w3\n",
    "    w1, w2, w3 = w1/total, w2/total, w3/total\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    ensemble_pred = w1 * lgb_val_pred + w2 * xgb_val_pred + w3 * cat_val_pred\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(y_val, ensemble_pred))\n",
    "\n",
    "print(\"Finding optimal ensemble weights...\")\n",
    "ensemble_study = optuna.create_study(direction='minimize')\n",
    "ensemble_study.optimize(ensemble_objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "# Get best weights (normalized)\n",
    "best_weights_raw = ensemble_study.best_params\n",
    "total_weight = sum(best_weights_raw.values())\n",
    "best_weights = {k: v/total_weight for k, v in best_weights_raw.items()}\n",
    "\n",
    "print(f\"\\nâœ“ Best Ensemble RMSE: {ensemble_study.best_value:.4f}\")\n",
    "print(f\"\\nOptimal Weights:\")\n",
    "print(f\"  LightGBM: {best_weights['lgb_weight']:.3f}\")\n",
    "print(f\"  XGBoost:  {best_weights['xgb_weight']:.3f}\")\n",
    "print(f\"  CatBoost: {best_weights['cat_weight']:.3f}\")\n",
    "\n",
    "# Improvement over best single model\n",
    "best_single = min(lgb_rmse, xgb_rmse, cat_rmse)\n",
    "improvement = best_single - ensemble_study.best_value\n",
    "print(f\"\\nImprovement over best single model: {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_predictions_header",
   "metadata": {},
   "source": [
    "## 7. Generate Final Ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "print(\"Generating ensemble predictions...\\n\")\n",
    "\n",
    "lgb_test_pred = lgb_model.predict(X_test_encoded)\n",
    "xgb_test_pred = xgb_model.predict(X_test_encoded)\n",
    "cat_test_pred = cat_model.predict(X_test_encoded)\n",
    "\n",
    "# Ensemble with optimal weights\n",
    "ensemble_pred = (\n",
    "    best_weights['lgb_weight'] * lgb_test_pred +\n",
    "    best_weights['xgb_weight'] * xgb_test_pred +\n",
    "    best_weights['cat_weight'] * cat_test_pred\n",
    ")\n",
    "\n",
    "print(\"Ensemble Prediction Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Min:    {ensemble_pred.min():.4f}\")\n",
    "print(f\"Max:    {ensemble_pred.max():.4f}\")\n",
    "print(f\"Mean:   {ensemble_pred.mean():.4f}\")\n",
    "print(f\"Median: {np.median(ensemble_pred):.4f}\")\n",
    "print(f\"Std:    {ensemble_pred.std():.4f}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'exam_score': ensemble_pred\n",
    "})\n",
    "\n",
    "# Validate\n",
    "assert len(submission) == len(test)\n",
    "assert submission['exam_score'].notna().all()\n",
    "print(\"\\nâœ“ Validation passed\")\n",
    "\n",
    "# Save\n",
    "submission.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE SUBMISSION CREATED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Filename: submission_ensemble.csv\")\n",
    "print(f\"Expected improvement: ~0.10-0.20 points\")\n",
    "print(f\"Target score: 8.53-8.63 (Top 5 range!)\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "display(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_header",
   "metadata": {},
   "source": [
    "## 8. Final Summary & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š Validation Performance:\")\n",
    "print(f\"  {'Model':<20} {'RMSE':<10} {'Rank'}\")\n",
    "print(\"-\"*70)\n",
    "results = [\n",
    "    ('LightGBM', lgb_rmse),\n",
    "    ('XGBoost', xgb_rmse),\n",
    "    ('CatBoost', cat_rmse),\n",
    "    ('Ensemble', ensemble_study.best_value)\n",
    "]\n",
    "results_sorted = sorted(results, key=lambda x: x[1])\n",
    "for rank, (model, rmse) in enumerate(results_sorted, 1):\n",
    "    emoji = 'ðŸ†' if rank == 1 else '  '\n",
    "    print(f\"  {emoji} {model:<20} {rmse:.4f}    #{rank}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Expected Leaderboard Impact:\")\n",
    "print(f\"  Previous score: 8.737\")\n",
    "print(f\"  Expected score: ~{ensemble_study.best_value:.3f} (validation)\")\n",
    "print(f\"  Target: Break into Top 5 (8.53-8.54)\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ If this doesn't break Top 5, try:\")\n",
    "print(f\"  1. More trials (200 per model)\")\n",
    "print(f\"  2. More feature engineering\")\n",
    "print(f\"  3. Cross-validation instead of single split\")\n",
    "print(f\"  4. Different random seeds and average submissions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Good luck! ðŸš€\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
